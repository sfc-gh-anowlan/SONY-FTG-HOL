{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "gnji4ebaooh2mopebe5h",
   "authorId": "8647371169770",
   "authorName": "ANOWLAN",
   "authorEmail": "anowlan@snowflake.com",
   "sessionId": "9ff06afb-63bd-4a62-a950-e8c5073a8538",
   "lastEditTime": 1749453096401
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "collapsed": false,
    "name": "PART1",
    "resultHeight": 316
   },
   "source": "## Task Graph Run scheduled during biz hours graph run to show:\n\nTransformation Concepts\n* Streams\n* Tasks\n* Dynamic Tables\n\nOrchestration & Workflow\n* DAG Structure\n* Graph Config Parameter\n* Task Return Value\n* Condition on Stream\n* Condition on Predecessor\n\nObservability\n* Retry Attempts\n* Event Logging\n* Query Tagging\n* SNS Task Notifications (optional)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246135ac-6f81-415d-948e-a17c4393b3eb",
   "metadata": {
    "language": "sql",
    "name": "define_schema"
   },
   "outputs": [],
   "source": "use role TASK_GRAPH_ROLE;\nuse schema TASK_GRAPH_DATABASE.TASK_GRAPH_SCHEMA;\n\n--this will show in query hitory and warehouse utilization filtering\nALTER SESSION SET query_tag = '{\"origin\":\"sf_hol\",\"name\":\"pde_demo\",\"version\":{\"major\":1, \"minor\":0},\"attributes\":{\"is_quickstart\":1, \"source\":\"notebook\", \"vignette\":\"tasks\"}}';\nALTER SESSION SET TIMEZONE = 'America/Los_Angeles';\nALTER SESSION SET LOG_LEVEL = INFO;\n\n-- OPTIONAL send notice to a slack channel\n-- call send_slack_message('The Task Graph Demo is starting at ' || CURRENT_TIME);"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "helper_function_runtime_randomize"
   },
   "outputs": [],
   "source": "--- function to randomize runtime with 1/10 as outlier (twice as long to show vairiable execution times in tasks)\ncreate or replace function RUNTIME_WITH_OUTLIERS(REGULAR_RUNTIME NUMBER(6,0))\nreturns NUMBER(6,0)\nlanguage SQL\ncomment = 'for input and output as milliseconds'\nas\n$$\n    select\n        case when uniform(1, 10, random()) = 10 \n            then cast((REGULAR_RUNTIME * 2 + (uniform(-10, 10, random()))/100 * REGULAR_RUNTIME) as NUMBER(6,0))\n            else cast((REGULAR_RUNTIME     + (uniform(-10, 10, random()))/100 * REGULAR_RUNTIME) as NUMBER(6,0))\n        end\n$$\n;"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "validate_helper_function"
   },
   "outputs": [],
   "source": "--- test randomized value around 5000 miliseconds\nselect RUNTIME_WITH_OUTLIERS(5000);\n"
  },
  {
   "cell_type": "code",
   "id": "3af4d56d-21fb-4458-ba53-b0bfd6d2741a",
   "metadata": {
    "language": "sql",
    "name": "gen_cust_purchase_function"
   },
   "outputs": [],
   "source": "create or replace function gen_cust_purchase(num_records number,ndays number)\nreturns table (custid number(10), purchase variant)\nlanguage python\nruntime_version=3.9\nhandler='genCustPurchase'\npackages = ('Faker')\nas $$\nfrom faker import Faker\nimport random\nfrom datetime import datetime, timedelta\n\nfake = Faker()\n\nclass genCustPurchase:\n    # Generate multiple customer purchase records\n    def process(self, num_records,ndays):       \n        for _ in range(num_records):\n            c_id = fake.random_int(min=1001, max=1999)\n            \n            #print(c_id)\n            customer_purchase = {\n                'custid': c_id,\n                'purchased': []\n            }\n            # Get the current date\n            current_date = datetime.now()\n            \n            # Calculate the maximum date (days from now)\n            min_date = current_date - timedelta(days=ndays)\n            \n            # Generate a random date within the date range\n            pdate = fake.date_between_dates(min_date,current_date)\n            \n            purchase = {\n                'prodid': fake.random_int(min=101, max=199),\n                'quantity': fake.random_int(min=1, max=5),\n                'purchase_amount': round(random.uniform(10, 1000),2),\n                'purchase_date': pdate\n            }\n            customer_purchase['purchased'].append(purchase)\n            \n            #customer_purchases.append(customer_purchase)\n            yield (c_id,purchase)\n\n$$;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5f13f98f-aebd-43ae-b7ce-ddd198438ea6",
   "metadata": {
    "language": "sql",
    "name": "generate_sales_data"
   },
   "outputs": [],
   "source": "-- loading 100 purchase records into table salesdata on first run only\ncreate table if not exists salesdata as\n    select * from\n          table(gen_cust_purchase(1000, 10));\n\n-- create a stream to trigger DEMO_TASK_8\ncreate stream if not exists DEMO_STREAM on table salesdata comment = 'stream on table as condition for product stock inventory DT';\nselect count(*) from salesdata;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e348061e-2722-4d4a-944a-c387458a37b1",
   "metadata": {
    "language": "sql",
    "name": "gen_prod_inv_function"
   },
   "outputs": [],
   "source": "-- function to generate product inventory data \ncreate or replace function gen_prod_inv(num_records number)\nreturns table (pid number(10), pname varchar(100), stock number(10,2), stockdate date)\nlanguage python\nruntime_version=3.9\nhandler='ProdTab'\npackages = ('Faker')\nas $$\nfrom faker import Faker\nimport random\nfrom datetime import datetime, timedelta\nfake = Faker()\n\nclass ProdTab:\n    # Generate multiple product records\n    def process(self, num_records):\n        product_id = 100 # Starting customer ID                 \n        for _ in range(num_records):\n            pid = product_id + 1\n            pname = fake.catch_phrase()\n            stock = round(random.uniform(500, 1000),0)\n            # Get the current date\n            current_date = datetime.now()\n            \n            # Calculate the maximum date (3 months from now)\n            min_date = current_date - timedelta(days=90)\n            \n            # Generate a random date within the date range\n            stockdate = fake.date_between_dates(min_date,current_date)\n\n            product_id += 1\n            yield (pid,pname,stock,stockdate)\n\n$$;\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c385b6ae-df00-44bf-bff3-c9445585058b",
   "metadata": {
    "language": "sql",
    "name": "gen_cust_info_function"
   },
   "outputs": [],
   "source": "-- function to generate customer test data \ncreate or replace function gen_cust_info(num_records number)\nreturns table (custid number(10), cname varchar(100), spendlimit number(10,2))\nlanguage python\nruntime_version=3.9\nhandler='CustTab'\npackages = ('Faker')\nas $$\nfrom faker import Faker\nimport random\n\nfake = Faker()\n# Generate a list of customers  \n\nclass CustTab:\n    # Generate multiple customer records\n    def process(self, num_records):\n        customer_id = 1000 # Starting customer ID                 \n        for _ in range(num_records):\n            custid = customer_id + 1\n            cname = fake.name()\n            spendlimit = round(random.uniform(1000, 10000),2)\n            customer_id += 1\n            yield (custid,cname,spendlimit)\n\n$$;\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3431e9d6-04fa-4ead-9103-fbd0dda7fbc0",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "demo_root_task_1"
   },
   "outputs": [],
   "source": "alter task if exists DEMO_TASK_1 suspend;\n\n---- successful root task running every hour during US business hours \ncreate or replace task DEMO_TASK_1 \nwarehouse = 'TASK_GRAPH_WH' \ncomment = ' root task running every hour during US Pacific business hours'\nschedule = 'USING CRON 15 8-18 * * MON-FRI America/Los_Angeles'\nSUSPEND_TASK_AFTER_NUM_FAILURES = 0\nTASK_AUTO_RETRY_ATTEMPTS = 0\n--- adding AWS SNS notification integration\n--ERROR_INTEGRATION = my_sns_notify_int\n--SUCCESS_INTEGRATION = my_sns_notify_int\n--- adding default config parameter for runtime duration multiplier\nconfig = $${\"RUNTIME_MULTIPLIER\": 5}$$                 \n\nas\n    declare\n        --- get runtime duration factor from graph config as integer\n        RUNTIME_MULTIPLIER integer := SYSTEM$GET_TASK_GRAPH_CONFIG('RUNTIME_MULTIPLIER');   \n        --- specify the median runtime in milliseconds\n        RANDOM_RUNTIME varchar := RUNTIME_WITH_OUTLIERS(:RUNTIME_MULTIPLIER * 1000);\n    begin\n        --- task will wait for a random duration with 1/10 being 2x as long\n       select SYSTEM$WAIT(:RANDOM_RUNTIME,'MILLISECONDS');                                      \n       call SYSTEM$SET_RETURN_VALUE('✅ All systems go in DEMO_TASK_1');\n       SYSTEM$LOG('INFO', 'DEMO_TASK_1: Event Log entry: root task sucessful!');\n    end\n;"
  },
  {
   "cell_type": "code",
   "id": "b9af5ad3-c645-4138-8181-4efc60d749be",
   "metadata": {
    "language": "sql",
    "name": "finalizer_task",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "--- Finalizer TASK to check all tables\ncreate or replace task DEMO_FINALIZER\nwarehouse = 'TASK_GRAPH_WH'\nfinalize = DEMO_TASK_1\nas\n    declare\n        RUNTIME_MULTIPLIER integer := SYSTEM$GET_TASK_GRAPH_CONFIG('RUNTIME_MULTIPLIER'); \n        --- get runtime duration factor from graph config as integer\n        RANDOM_RUNTIME varchar := RUNTIME_WITH_OUTLIERS(:RUNTIME_MULTIPLIER * 1000);      \n        --- specify the median runtime in milliseconds\n    begin\n       select SYSTEM$WAIT(:RANDOM_RUNTIME,'MILLISECONDS');                               \n       --- task will wait for a random duration with 1/10 being twice as long\n       call SYSTEM$SET_RETURN_VALUE('✅ All checks completed via DEMO_FINALIZER');\n       SYSTEM$LOG('INFO', 'DEMO_FINALIZER: completed!');\n       --- demo return value to show in the UI\n     end\n;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e2b983-1d52-4fe1-8ecc-f38b8f21dd68",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "load_prod_stock_task",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- successful task with random duration\ncreate or replace task DEMO_TASK_2 \nwarehouse = 'TASK_GRAPH_WH' \ncomment = 'successful task loading data into prod_stock_inv'\nafter\n    DEMO_TASK_1 \nas\n    begin\n       --- loading data into prod_stock_inv with stored proc\n       create or replace table prod_stock_inv as select * from table(gen_prod_inv(1000)) order by 1; \n       call SYSTEM$SET_RETURN_VALUE('DEMO_TASK_2: table prod_stock_inv loaded with data');\n        SYSTEM$LOG('INFO', 'DEMO_TASK_2: completed!');\n    end\n;"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07d190b-e580-4cc0-9e43-25f6b1e77848",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "load_cust_info_task",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "--- successful task calling a stored procedure to build cust_info table\ncreate or replace task DEMO_TASK_3 \nwarehouse = 'TASK_GRAPH_WH' \ncomment = 'successful task loading data into cust_info after random wait'\nafter\n    DEMO_TASK_1\nas\n    \n    begin\n        --- demo loading data into cust_info with stored proc\n        create or replace table cust_info as select * from table(gen_cust_info(1000)) order by 1; \n        call SYSTEM$SET_RETURN_VALUE('DEMO_TASK_3: data loaded into cust_info table');\n        SYSTEM$LOG('INFO', 'DEMO_TASK_3: completed!');\n    end\n;"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccde2424-4b1f-4937-aa3c-b69d45f6b6b2",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "sum_table_task"
   },
   "outputs": [],
   "source": "-- successful task creating sproc\ncreate or replace task DEMO_TASK_4 \nwarehouse = 'TASK_GRAPH_WH' \ncomment = 'task to define a function sum_table function to be used in DT'\nafter\n  DEMO_TASK_2 \nas \ndeclare \n    RUNTIME_MULTIPLIER integer;\n    RANDOM_RUNTIME varchar;\nbegin \n--- function to keep a running total used in dynamic table\nCREATE OR REPLACE FUNCTION sum_table (INPUT_NUMBER number)\n  returns TABLE (running_total number)\n  language python\n  runtime_version = '3.9'\n  handler = 'gen_sum_table'\nas\n$$\n\n# Define handler class\nclass gen_sum_table :\n\n  ## Define __init__ method ro initilize the variable\n  def __init__(self) :    \n    self._running_sum = 0\n  \n  ## Define process method\n  def process(self, input_number: float) :\n    # Increment running sum with data from the input row\n    new_total = self._running_sum + input_number\n    self._running_sum = new_total\n\n    yield(new_total,)\n  \n$$\n;\nSYSTEM$LOG('INFO', 'DEMO_TASK_4: completed!');\nend;"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ce6c84-126d-4af2-bcf7-6a08fd60691d",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "CDTAS_customer_data_sales_history_tasktask",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "create or replace task DEMO_TASK_5 \ncomment = 'serverless task creating the customer_sales_data_history dynamic table'\nafter\n    DEMO_TASK_1, DEMO_TASK_4 \nwhen \n    SYSTEM$STREAM_HAS_DATA('DEMO_STREAM') \nas\n    begin\n         --lets create a dynamic table for sales history\n        CREATE OR REPLACE DYNAMIC TABLE customer_sales_data_history\n            LAG='DOWNSTREAM'\n            WAREHOUSE=TASK_GRAPH_WH\n                AS\n                select \n                    s.custid as customer_id,\n                    c.cname as customer_name,\n                    s.purchase:\"prodid\"::number(5) as product_id,\n                    s.purchase:\"purchase_amount\"::number(10) as saleprice,\n                    s.purchase:\"quantity\"::number(5) as quantity,\n                    s.purchase:\"purchase_date\"::date as salesdate\n                from\n                    cust_info c inner join salesdata s on c.custid = s.custid;\n                    \n        call SYSTEM$SET_RETURN_VALUE('DEMO_TASK_5: created customer_sales_data_history DT');\n        SYSTEM$LOG('INFO', 'DEMO_TASK_5: completed!');\n    end\n;"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53957c2-5823-45a9-9ef4-3c2df96d02f7",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "task_6"
   },
   "outputs": [],
   "source": "--- successful task calling a system function to send a random return value 1/2/3\n\ncreate or replace task DEMO_TASK_6 \nwarehouse = 'TASK_GRAPH_WH' \ncomment = 'successful task calling a system function to send a random return value 1, 2 or 3'\nafter\n    DEMO_TASK_3 \nas\n    declare\n        RANDOM_VALUE varchar;\n    begin\n        RANDOM_VALUE := (select UNIFORM(1, 3, RANDOM()));\n        case when :RANDOM_VALUE = 1\n        then\n            call SYSTEM$SET_RETURN_VALUE('✅ Quality Check Passed');\n        else\n            call SYSTEM$SET_RETURN_VALUE('⚠️ Quality Check Failed from random gen function in Task 6');\n        end;\n        SYSTEM$LOG('INFO', 'DEMO_TASK_6: completed!');\n    end;\n;"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa399d58-8ac4-453d-830f-b5613eab48f5",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "CDTAS_salesreport_task"
   },
   "outputs": [],
   "source": "--- failing task with first procedure succeeding and second procedure failing 1/4 cases\n\ncreate or replace task DEMO_TASK_7\nwarehouse = 'TASK_GRAPH_WH' \ncomment = 'failing task with first procedure because customer_sales_data_history may not exist yet'\nafter\n    DEMO_TASK_4 \nas\n    begin\n        --create new \n        CREATE OR REPLACE DYNAMIC TABLE salesreport\n            LAG = '1 MINUTE'\n            WAREHOUSE=TASK_GRAPH_WH\n            AS\n            Select\n                t1.customer_id,\n                t1.customer_name, \n                t1.product_id,\n                p.pname as product_name,\n                t1.saleprice,\n                t1.quantity,\n                (t1.saleprice/t1.quantity) as unitsalesprice,\n                t1.salesdate as CreationTime,\n                customer_id || '-' || t1.product_id  || '-' || t1.salesdate AS CUSTOMER_SK,\n                LEAD(CreationTime) OVER (PARTITION BY t1.customer_id ORDER BY CreationTime ASC) AS END_TIME\n            from \n                customer_sales_data_history t1 inner join prod_stock_inv p \n                on t1.product_id = p.pid;\n        SYSTEM$LOG('INFO', 'DEMO_TASK_7: CTAS salesreport dynamic table complete');\n        call SYSTEM$SET_RETURN_VALUE('DEMO_TASK_7: created salesreport DT');\n    end\n;"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca403c49-b916-4a00-9562-53a38619a719",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "CDTAS_prod_inv_alert_task"
   },
   "outputs": [],
   "source": "--- skipped task when stream condition is not met\n\ncreate or replace task DEMO_TASK_8\nwarehouse = 'TASK_GRAPH_WH' \ncomment ='skipped task when stream condition is not met'\nafter\n    DEMO_TASK_6,\n    DEMO_TASK_7\nas\n   begin\n        CREATE OR REPLACE DYNAMIC TABLE PROD_INV_ALERT\n        LAG = '1 MINUTE'\n        WAREHOUSE=TASK_GRAPH_WH\n        AS\n        SELECT \n            S.PRODUCT_ID, \n            S.PRODUCT_NAME,CREATIONTIME AS LATEST_SALES_DATE,\n            STOCK AS BEGINING_STOCK,\n            SUM(S.QUANTITY) OVER (PARTITION BY S.PRODUCT_ID ORDER BY CREATIONTIME) TOTALUNITSOLD, \n            (STOCK - TOTALUNITSOLD) AS UNITSLEFT,\n            ROUND(((STOCK-TOTALUNITSOLD)/STOCK) *100,2) PERCENT_UNITLEFT,\n            CURRENT_TIMESTAMP() AS ROWCREATIONTIME\n        FROM SALESREPORT S JOIN PROD_STOCK_INV ON PRODUCT_ID = PID\n        QUALIFY ROW_NUMBER() OVER (PARTITION BY PRODUCT_ID ORDER BY CREATIONTIME DESC) = 1;\n        \n        SYSTEM$LOG('INFO', 'DEMO_TASK_8: CTAS PROD_INV_ALERT dynamic table complete');\n    end\n;"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818a6514-2beb-4d6e-a6cb-feca3d625bfb",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "task_9"
   },
   "outputs": [],
   "source": "--- task skipped 1/3 times, if TASK_6 returns '3' \n\ncreate or replace task DEMO_TASK_9\nwarehouse = 'TASK_GRAPH_WH' \ncomment = 'task skipped 1/3 times, if TASK_6 returns passed'\n\nafter\n  DEMO_TASK_6 \n  as declare \n    PREDECESSOR_VALUE varchar;\n    RUNTIME_MULTIPLIER integer;\n    RANDOM_RUNTIME varchar;\nbegin PREDECESSOR_VALUE := SYSTEM$GET_PREDECESSOR_RETURN_VALUE('DEMO_TASK_6');\ncase\n    when :PREDECESSOR_VALUE = '✅ Quality Check Passed' \n        then \n            RUNTIME_MULTIPLIER := SYSTEM$GET_TASK_GRAPH_CONFIG('RUNTIME_MULTIPLIER');\n            RANDOM_RUNTIME := RUNTIME_WITH_OUTLIERS(:RUNTIME_MULTIPLIER * 3000);\n            select\n                SYSTEM$WAIT(:RANDOM_RUNTIME, 'MILLISECONDS');\n                call SYSTEM$SET_RETURN_VALUE('Delay: ' || :RANDOM_RUNTIME || ' milliseconds');\n        else \n            SYSTEM$LOG('ERROR', 'DEMO_TASK_9: ' || :PREDECESSOR_VALUE);\n            call SYSTEM$SET_RETURN_VALUE('Task skipped due to failed quality check in DEMO_TASK_6');\n  end case;\n  SYSTEM$LOG('INFO', 'DEMO_TASK_9: completed!');\n  end;"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8627d03f-8d38-4535-bffa-9c53762c2e07",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "task_10",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "--- task self-cancelling 1/10 times after long run\ncreate or replace task DEMO_TASK_10\nwarehouse = 'TASK_GRAPH_WH'\ncomment = 'task self-cancelling 1/10 times after long run'\nafter\n    DEMO_TASK_3 \nas\n    declare\n        RANDOM_VALUE number(2,0);\n    begin\n        RANDOM_VALUE := (select UNIFORM(1, 10, RANDOM()));\n        if (:RANDOM_VALUE = 10) then\n            select SYSTEM$WAIT(12);\n            SYSTEM$LOG('ERROR', 'DEMO_TASK_10: Canceling Execution');\n            select SYSTEM$USER_TASK_CANCEL_ONGOING_EXECUTIONS('DEMO_TASK_12');\n            CALL SYSTEM$SET_RETURN_VALUE('DEMO_TASK_10: Canceled by task');\n        end if;\n        \n        select SYSTEM$WAIT(2);\n        SYSTEM$LOG('INFO', 'DEMO_TASK_10: completed!');\n    end\n;"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff516ff4-7111-43e9-abee-9516f7d0b1c4",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "CDTAS_cumulative_purchase_task"
   },
   "outputs": [],
   "source": "--- successful task with 2 predecessors\ncreate or replace task DEMO_TASK_11\nwarehouse = 'TASK_GRAPH_WH'\ncomment = 'successful task CTAS cumulative_purchase dynamic table'\nafter\n    DEMO_TASK_10,\n    DEMO_TASK_2\nas\n    begin \n        CREATE OR REPLACE DYNAMIC TABLE cumulative_purchase\n        LAG = '1 MINUTE'\n        WAREHOUSE=TASK_GRAPH_WH\n        AS\n            select \n                month(creationtime) monthNum,\n                year(creationtime) yearNum,\n                customer_id, \n                saleprice,\n                running_total \n            from \n                salesreport,\n                table(sum_table(saleprice) over (partition by creationtime,customer_id order by creationtime, customer_id));\n            \n        CALL SYSTEM$SET_RETURN_VALUE('DEMO_TASK_11: cumulative_purchase dynamic table created');\n        SYSTEM$LOG('INFO', 'DEMO_TASK_11: completed!');\n    end\n;"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e615dce-b99e-497c-9e78-5e4b2adea78e",
   "metadata": {
    "language": "sql",
    "name": "inventory_alert_task"
   },
   "outputs": [],
   "source": "--- suspended task on first run\ncreate or replace task DEMO_TASK_12\nwarehouse = 'TASK_GRAPH_WH'\ncomment = 'enable Low Inventory Alert'\nafter\n    DEMO_TASK_9\nas\nbegin\n    CREATE OR REPLACE ALERT alert_low_inv\n    WAREHOUSE = TASK_GRAPH_WH\n    SCHEDULE = '5 MINUTE'\n    IF (EXISTS (\n        SELECT *\n        FROM prod_inv_alert\n        WHERE percent_unitleft < 10 and ROWCREATIONTIME >           SNOWFLAKE.ALERT.LAST_SUCCESSFUL_SCHEDULED_TIME()\n            )\n        )\n    THEN\n        begin\n            -- Optional Slack Alert\n            --CALL send_slack_message('Alert: Low Inventory of products. Check the inventory report in Snowflake table prod_inv_alert.');\n            SYSTEM$LOG('ERROR', 'DEMO_TASK_12: Alert: Low Inventory of products. Check the inventory report in prod_inv_alert!');\n        end\n        ;\n;\nend"
  },
  {
   "cell_type": "markdown",
   "id": "9a5e0820-9976-4b20-8393-4cdfc6e76633",
   "metadata": {
    "name": "READY_TO_TEST",
    "collapsed": false
   },
   "source": "Now we have built out the DAG with several paths and interdepenancies. \n\nWe are ready to test. For the first run lets introduce a suspended demo_task_12 to see the results in the intial run."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b7f489-2777-4071-8fdf-b2abc8a7cc9d",
   "metadata": {
    "language": "sql",
    "name": "resume_and_run_with_errors"
   },
   "outputs": [],
   "source": "--suspend 1 \nalter task DEMO_TASK_1 suspend;\n--enable all tasks in the graph \nselect SYSTEM$TASK_DEPENDENTS_ENABLE('DEMO_TASK_1');\n--suspend DEMO_TASK_1 == root\nalter task DEMO_TASK_1 suspend;\n\n--suspend DEMO_TASK_12 only to see the results on the first run\nalter task DEMO_TASK_12 suspend;\n\n---  resume 1 and execute\nalter task DEMO_TASK_1 resume;\nexecute task DEMO_TASK_1;"
  },
  {
   "cell_type": "markdown",
   "id": "adc6c000-786d-45a5-bccd-a845e4047ebc",
   "metadata": {
    "name": "MONITOR_FIRST_RUN",
    "collapsed": false
   },
   "source": "## Check Snowsight -> Monitoring -> Task History\n\nNow lets look at the DAG execution and results in Snowsight -> Monitoring -> Task History to watch the status and see results.\n\n## Check Snowsight -> Monitoring -> Traces & Logs\n\nCome back here to fix any errors and try again. \n\n\nYou should see \n    \n    DEMO_TASK_5 may be skipped because DEMO_STREAM is empty\n    DEMO_TASK_7 may fail a dependancy and require retry\n    DEMO_TASK_8 did not run since 7 predecessor 8 fails\n    DEMO_TASK_11 may fail a dependancy and require retry\n    DEMO_TASK_12 is suspended "
  },
  {
   "cell_type": "markdown",
   "id": "4fe53085-d631-4da8-a69f-4f3274d72381",
   "metadata": {
    "name": "PART2",
    "collapsed": false
   },
   "source": "## PART 2\nTask Graph corrections and run two\n\nTransformation Concepts\n* Streams\n* Tasks\n\nOrchestration & Workflow\n* DAG Structure\n* Task Return Value\n* Condition on Stream\n* Condition on Predecessor\n\nObservability\n* Event Logging\n* SNS Task Notifications (optional)"
  },
  {
   "cell_type": "code",
   "id": "4f79ea57-859b-40de-9e64-9e3a8357fd75",
   "metadata": {
    "language": "sql",
    "name": "fix_task_7_and_task_11"
   },
   "outputs": [],
   "source": "--suspend the task graph to make changes\nalter task DEMO_TASK_1 suspend;\n\n--- Update to make task 8 a dependancy\ncreate or replace task DEMO_TASK_7\nwarehouse = 'TASK_GRAPH_WH' \ncomment = 'failing task with first procedure because customer_sales_data_history may not exist yet'\nafter\n    DEMO_TASK_4,\n    DEMO_TASK_5  --lets add this dependancy since we need the customer_sales_data_history\nas\n    begin\n        --create new \n        CREATE OR REPLACE DYNAMIC TABLE salesreport\n            LAG = '1 MINUTE'\n            WAREHOUSE=TASK_GRAPH_WH\n            AS\n            Select\n                t1.customer_id,\n                t1.customer_name, \n                t1.product_id,\n                p.pname as product_name,\n                t1.saleprice,\n                t1.quantity,\n                (t1.saleprice/t1.quantity) as unitsalesprice,\n                t1.salesdate as CreationTime,\n                customer_id || '-' || t1.product_id  || '-' || t1.salesdate AS CUSTOMER_SK,\n                LEAD(CreationTime) OVER (PARTITION BY t1.customer_id ORDER BY CreationTime ASC) AS END_TIME\n            from \n                customer_sales_data_history t1 inner join prod_stock_inv p \n                on t1.product_id = p.pid;\n        SYSTEM$LOG('INFO', 'DEMO_TASK_7: CTAS salesreport dynamic table complete');\n        call SYSTEM$SET_RETURN_VALUE('DEMO_TASK_7: created salesreport DT');\n    end\n;\n\n--- Update to make task 11 a dependancy\ncreate or replace task DEMO_TASK_11\nwarehouse = 'TASK_GRAPH_WH'\ncomment = 'successful task CTAS cumulative_purchase dynamic table'\nafter\n    DEMO_TASK_10,\n    DEMO_TASK_7, --lets add this dependancy since we need the salesreport first\n    DEMO_TASK_2\nas\n    begin \n        CREATE OR REPLACE DYNAMIC TABLE cumulative_purchase\n        LAG = '1 MINUTE'\n        WAREHOUSE=TASK_GRAPH_WH\n        AS\n            select \n                month(creationtime) monthNum,\n                year(creationtime) yearNum,\n                customer_id, \n                saleprice,\n                running_total \n            from \n                salesreport,\n                table(sum_table(saleprice) over (partition by creationtime,customer_id order by creationtime, customer_id));\n            \n        CALL SYSTEM$SET_RETURN_VALUE('DEMO_TASK_11: cumulative_purchase dynamic table created');\n        SYSTEM$LOG('INFO', 'DEMO_TASK_11: completed!');\n    end\n;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4ed93344-148a-4577-bfc4-5a4f953fefa7",
   "metadata": {
    "language": "sql",
    "name": "insert_sales_run_clean"
   },
   "outputs": [],
   "source": "-- Add 10k new sales records for change stream DEMO_STREAM on TASK_5\ninsert into salesdata select * from table(gen_cust_purchase(10000,2));\n\n---  resume 1 and execute ALL\nselect SYSTEM$TASK_DEPENDENTS_ENABLE('DEMO_TASK_1');\n\nalter task DEMO_TASK_1 resume;\nexecute task DEMO_TASK_1;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "93c219ed-736a-40ae-b36e-3ac32fde4b2a",
   "metadata": {
    "name": "PART3",
    "collapsed": false
   },
   "source": "## PART 3\nDyanmic Tables Monitoring:\n\nOrchestration & Workflows\n* CUSTOMER_SALES_DATA \n* SALESREPORT\n* CUMULATIVE_PURCHASE\n* PROD_INV_ALERT\n\n\nObservability\n* Create Alert\n* Insert Data and monitor\n* View in Streamlit\n* Update Table Definition\n* OPTIONAL: Generate Slack alert"
  },
  {
   "cell_type": "code",
   "id": "033dcb11-5b0d-431c-8c78-71af8787bfd3",
   "metadata": {
    "language": "python",
    "name": "monitor_inventory",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import streamlit as st\nimport altair as alt\nfrom snowflake.snowpark.context import get_active_session\n\n# Get active Snowflake session\nsession = get_active_session()\n\n# App title\nst.title(\"Sales and Inventory Dashboard\")\n\n# Create two columns for the layout\ncol1, col2 = st.columns(2)\n\nwith col1:\n    st.header(\"Cumulative Purchases\")\n    \n    # Query cumulative purchase data\n    cumulative_df = session.sql(\"\"\"\n        SELECT \n            MONTHNUM,\n            YEARNUM,\n            SUM(SALEPRICE) as TOTAL_SALES,\n            COUNT(DISTINCT CUSTOMER_ID) as CUSTOMER_COUNT\n        FROM CUMULATIVE_PURCHASE\n        GROUP BY MONTHNUM, YEARNUM\n        ORDER BY YEARNUM, MONTHNUM\n    \"\"\").to_pandas()\n    \n    # Create monthly sales bar chart\n    sales_chart = alt.Chart(cumulative_df).mark_bar().encode(\n        x=alt.X('MONTHNUM:O', title='Month'),\n        y=alt.Y('TOTAL_SALES:Q', title='Total Sales'),\n        color=alt.Color('YEARNUM:N', title='Year')\n    ).properties(height=300)\n    \n    st.altair_chart(sales_chart, use_container_width=True)\n\n\nwith col2:\n    st.header(\"Inventory Alerts\")\n    \n    # Query inventory alert data\n    inventory_df = session.sql(\"\"\"\n        SELECT \n            PRODUCT_ID,\n            PRODUCT_NAME,\n            UNITSLEFT,\n            PERCENT_UNITLEFT\n        FROM PROD_INV_ALERT\n        WHERE PERCENT_UNITLEFT < 50\n        ORDER BY PERCENT_UNITLEFT ASC\n    \"\"\").to_pandas()\n    \n    # Create inventory status chart\n    inventory_chart = alt.Chart(inventory_df).mark_bar().encode(\n        x=alt.X('PRODUCT_NAME:N', title='Product', sort='-y'),\n        y=alt.Y('PERCENT_UNITLEFT:Q', title='Inventory Remaining (%)'),\n        color=alt.condition(\n            alt.datum.PERCENT_UNITLEFT < 10,\n            alt.value('red'),\n            alt.value('orange')\n        )\n    ).properties(height=300)\n    \n    st.altair_chart(inventory_chart, use_container_width=True)\n\n# Display summary metrics\nst.header(\"Summary Statistics\")\ncol3, col4, col5, col6 = st.columns(4)\n\n# Get summary metrics\nmetrics = session.sql(\"\"\"\n    SELECT \n        COUNT(DISTINCT CUSTOMER_ID) as TOTAL_CUSTOMERS,\n        SUM(SALEPRICE) as TOTAL_REVENUE,\n        COUNT(*) as TOTAL_TRANSACTIONS,\n        AVG(SALEPRICE) as AVG_TRANSACTION\n    FROM CUMULATIVE_PURCHASE\n\"\"\").collect()[0]\n\ncol3.metric(\"Total Customers\", f\"{metrics['TOTAL_CUSTOMERS']:,.0f}\")\ncol4.metric(\"Total Revenue\", f\"${metrics['TOTAL_REVENUE']:,.2f}\")\ncol5.metric(\"Total Transactions\", f\"{metrics['TOTAL_TRANSACTIONS']:,.0f}\")\ncol6.metric(\"Avg Transaction\", f\"${metrics['AVG_TRANSACTION']:,.2f}\")\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "78f2d4ac-6a19-4188-9302-9cb76fb0c657",
   "metadata": {
    "name": "cdc_change",
    "collapsed": false
   },
   "source": "Now we can make an Alert trigger, Log an Error (optioanally send a Slack) when inventory drops below 10%;"
  },
  {
   "cell_type": "code",
   "id": "8e351474-83a3-4e6d-b8ad-f540395a25b8",
   "metadata": {
    "language": "sql",
    "name": "GENERATE_SALES_ALERT",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- Alerts are pause by default, so let's resume to check in 5 mins\nALTER ALERT alert_low_inv RESUME;\n\n-- Add new records and check our \ninsert into salesdata select * from table(gen_cust_purchase(4000,2));",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d37369dd-57c6-4397-90c0-3f98a79f0cea",
   "metadata": {
    "language": "sql",
    "name": "MONITOR_ALERTS"
   },
   "outputs": [],
   "source": "SELECT\n  NAME,ACTION,STATE,SCHEDULED_TIME,COMPLETED_TIME\nFROM\n  TABLE (INFORMATION_SCHEMA.ALERT_HISTORY ())\nWHERE\n  NAME = 'ALERT_LOW_INV'\n  AND STATE IN ('SCHEDULED', 'TRIGGERED')\nORDER BY\n  SCHEDULED_TIME DESC limit 4;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "074a0269-4df9-4cae-b154-4e135287d1ff",
   "metadata": {
    "language": "sql",
    "name": "check_prod_inv_ten_precent"
   },
   "outputs": [],
   "source": "-- Add new records and confirm Dynamic tables propagate changes\nselect * from prod_inv_alert where PERCENT_UNITLEFT < 10;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "89decca0-dd4f-4494-8a3b-1ce4b689bafb",
   "metadata": {
    "language": "sql",
    "name": "suspend_processes"
   },
   "outputs": [],
   "source": "-- Alerts are pause by default, so let's resume it first\nALTER ALERT alert_low_inv SUSPEND;\nalter task DEMO_TASK_1 SUSPEND;\n\n--clean up\n--DROP TABLE TASK_GRAPH_DATABASE.TASK_GRAPH_SCHEMA.CUMULATIVE_PURCHASE;\n--DROP TABLE TASK_GRAPH_DATABASE.TASK_GRAPH_SCHEMA.CUST_INFO;\n--DROP TABLE TASK_GRAPH_DATABASE.TASK_GRAPH_SCHEMA.CUSTOMER_SALES_DATA_HISTORY;\n--DROP TABLE TASK_GRAPH_DATABASE.TASK_GRAPH_SCHEMA.PROD_STOCK_INV;\n--DROP TABLE TASK_GRAPH_DATABASE.TASK_GRAPH_SCHEMA.SALESREPORT;\n--DROP TABLE TASK_GRAPH_DATABASE.TASK_GRAPH_SCHEMA.SALESDATA;\n--DROP STREAM TASK_GRAPH_DATABASE.TASK_GRAPH_SCHEMA.DEMO_STREAM;",
   "execution_count": null
  }
 ]
}